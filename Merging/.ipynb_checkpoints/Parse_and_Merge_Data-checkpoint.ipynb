{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Json + CSV 데이터 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n",
      "['_JSON 1 Instagram JSON File/1day1poem.json', '_JSON 1 Instagram JSON File/9_ruumy.json', '_JSON 1 Instagram JSON File/ajaegeul.json', '_JSON 1 Instagram JSON File/book_jjung.json', '_JSON 1 Instagram JSON File/by_yell7.json']\n",
      "\n",
      "70\n",
      "['_JSON 2 Image OCR Result CSV File/1day1poem.csv', '_JSON 2 Image OCR Result CSV File/9_ruumy.csv', '_JSON 2 Image OCR Result CSV File/ajaegeul.csv', '_JSON 2 Image OCR Result CSV File/book_jjung.csv', '_JSON 2 Image OCR Result CSV File/by_yell7.csv']\n"
     ]
    }
   ],
   "source": [
    "# 상위 폴더로부터 하위 디렉토리 리스트로 뽑아주는 함수\n",
    "def load_directory_data(pwd):\n",
    "\n",
    "    file_path_list = []\n",
    "    \n",
    "    # 디렉토리, 디렉토리 내 폴더 리스트, 파일 리스트\n",
    "    for path,dirs,files in os.walk(pwd):\n",
    "        \n",
    "        for f in files:           \n",
    "            file_path = path + '/' +f\n",
    "            file_path_list.append(file_path) \n",
    "            \n",
    "    print(len(file_path_list))\n",
    "    return file_path_list\n",
    "\n",
    "FILE_1 = load_directory_data(\"_JSON 1 Instagram JSON File\")\n",
    "print(FILE_1[:5])\n",
    "print()\n",
    "FILE_2 = load_directory_data(\"_JSON 2 Image OCR Result CSV File\")\n",
    "print(FILE_2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(FILE_PATH):\n",
    "    \n",
    "    # read json\n",
    "    with open(FILE_PATH, encoding='UTF8') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "        \n",
    "    user_name = os.path.basename(FILE_PATH)[:-5]\n",
    "    insta_df = pd.DataFrame()\n",
    "\n",
    "    for d in json_data:\n",
    "        hashtag_list = []\n",
    "        caption_txt = ''\n",
    "        insta = pd.DataFrame()\n",
    "\n",
    "        # caption 해시태그 가져오기\n",
    "        if 'caption' in d:\n",
    "            # 간단한 전처리\n",
    "            caption_txt = d['caption'].replace('\\n',' ')\n",
    "            if caption_txt[0] == '-':\n",
    "                caption_txt = caption_txt[1:]\n",
    "            caption_txt = caption_txt.strip()\n",
    "            hashtag_list = re.findall(r\"#(\\w+)\", caption_txt) \n",
    "\n",
    "        # 기존 코드는 caption이 없을 경우 작동 못함\n",
    "        # comments에서 해시태그 가져오기 \n",
    "        if 'comments' in d:\n",
    "            comments = d['comments']\n",
    "            for c in list(d['comments']):\n",
    "                # 댓글 작성자가 인스타 유저라면 코멘트 가져오기\n",
    "                if c['author'] == userName:\n",
    "                    comment_txt = c['comment']\n",
    "                    hashtag_list = re.findall(r\"#(\\w+)\", comment_txt)   \n",
    "                    #태그가 저장이 되었다면 for 문 종료\n",
    "                    if len(hashtag_list) != 0:\n",
    "                        break\n",
    "        \n",
    "        # 매 loop마다 데이터 쌓기\n",
    "        insta = pd.DataFrame({'USER_ID': user_name,\n",
    "                              'CONTENT_ID': d['key'].split('/')[-2],\n",
    "                              'Content_txt': caption_txt,\n",
    "                              'Hashtags' : [hashtag_list]})\n",
    "        insta_df = insta_df.append(insta)\n",
    "        insta_df = insta_df.reset_index(drop=True)\n",
    "\n",
    "    return insta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_csv(FILE_PATH):\n",
    "    data = pd.read_csv(FILE_PATH,encoding = 'utf-8' )\n",
    "    data = data.iloc[:,:2]\n",
    "    data.columns = ['CONTENT_IMAGE_ID','Image_Content_txt']\n",
    "    # 게시글 아이디 \n",
    "    data['CONTENT_IMAGE_ID'] = data['CONTENT_IMAGE_ID'].apply(lambda x : x[:-4])\n",
    "    # 게시글에 여러장 있을 경우 추가 구분\n",
    "    data['CONTENT_ID'] =  data['CONTENT_IMAGE_ID'].apply(lambda x : x[:-2])\n",
    "    data['USER_ID'] = os.path.basename(FILE_PATH)[:-4]\n",
    "    data = data[['USER_ID','CONTENT_ID','CONTENT_IMAGE_ID','Image_Content_txt']]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1day1poem\n",
      "9_ruumy\n",
      "ajaegeul\n",
      "book_jjung\n",
      "by_yell7\n",
      "chaemss\n",
      "choejemin_pvc\n",
      "choi_dol\n",
      "churihyung\n",
      "c___w00\n",
      "dajeong_geul\n",
      "day_in_scene\n",
      "dden_by\n",
      "dearbliss2\n",
      "deep_bak\n",
      "dh_solace\n",
      "doodler_1211\n",
      "funnyprince81\n",
      "galin001\n",
      "geulgomm\n",
      "guitarlist._w.g\n",
      "hanl_i\n",
      "haru11__\n",
      "haru_line\n",
      "h_01_00_a\n",
      "h_jongduck\n",
      "iamkimbunny\n",
      "insightsh\n",
      "insta_book_cafe\n",
      "insum_\n",
      "iris_daily_writing\n",
      "jaulounge\n",
      "jea.therapy\n",
      "jinagann\n",
      "jinsimgeul\n",
      "jms14219\n",
      "kiheaven97\n",
      "kim_friendship_01.19\n",
      "kim_hanwoong\n",
      "laenari\n",
      "marom__story\n",
      "me______new\n",
      "moonfatalae\n",
      "namumind\n",
      "ok_yeong_\n",
      "poem_1000_\n",
      "reason_that_i_live\n",
      "riosniper114\n",
      "seesaw517\n",
      "see_min0727\n",
      "seodeokjun\n",
      "seokgeul\n",
      "shine_like_september\n",
      "syhiphop\n",
      "taeeeseok\n",
      "taehee_editor\n",
      "tale_tree_\n",
      "violet_hoho\n",
      "w.gahee\n",
      "w.ojoo\n",
      "wan_e0612\n",
      "woojin_940205\n",
      "worker_poet\n",
      "writer.jieun\n",
      "writing_peach.97\n",
      "youandme.211\n",
      "yumradio\n",
      "_illusion_30\n",
      "_neobam\n",
      "총 데이터 개수 31613\n"
     ]
    }
   ],
   "source": [
    "def merging(FILE_LIST1,FILE_LIST2):\n",
    "    total_data = 0\n",
    "    for f_json in FILE_LIST1:\n",
    "        user_json = os.path.basename(f_json)[:-5]\n",
    "        insta_data = read_json(f_json)\n",
    "        for f_csv in FILE_LIST2:\n",
    "            user_csv = os.path.basename(f_csv)[:-4]\n",
    "            # 유저 같다면\n",
    "            if user_json == user_csv:\n",
    "                ocr_data = read_csv(f_csv)\n",
    "                print(user_csv)\n",
    "                merge_df = pd.merge(insta_data,ocr_data,on=['USER_ID','CONTENT_ID'],how='inner')\n",
    "                merge_df = merge_df[['USER_ID','CONTENT_ID','CONTENT_IMAGE_ID','Image_Content_txt','Content_txt','Hashtags']]\n",
    "                merge_df.to_csv('Final_Data/' + user_json + '.csv', encoding='utf-8-sig')\n",
    "                total_data += len(merge_df)\n",
    "    print(\"총 데이터 개수\",total_data)\n",
    "merging(FILE_1,FILE_2)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전체 데이터로 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>CONTENT_ID</th>\n",
       "      <th>CONTENT_IMAGE_ID</th>\n",
       "      <th>Image_Content_txt</th>\n",
       "      <th>Content_txt</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1day1poem</td>\n",
       "      <td>B3B7tNPFOhY</td>\n",
       "      <td>B3B7tNPFOhY_0</td>\n",
       "      <td>벌레 물어 가렵다면 할머니 침을 발라주셨다. 쪼그려 앉아 다리 저릴 때도 할머니 코...</td>\n",
       "      <td>벌레 물어 가렵다면 할머니 침을 발라주셨다.  쪼그려 앉아 다리 저릴 때도 할머니 ...</td>\n",
       "      <td>['가능하면1일1시', '190825', '임재건', '1일1시', '다시는사랑이없...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1day1poem</td>\n",
       "      <td>B3A90BZlUGb</td>\n",
       "      <td>B3A90BZlUGb_0</td>\n",
       "      <td>들에 억새가 은발에 구부정하니 할매 닮아서 할매랑 들에 가면 할매 못 찾겠네. -할...</td>\n",
       "      <td>들에 억새가 은발에 구부정하니 할매 닮아서  할매랑 들에 가면 할매 못 찾겠네. -...</td>\n",
       "      <td>['가능하면1일1시', '190930', '임재건', '1일1시', '다시는사랑이없...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1day1poem</td>\n",
       "      <td>B2_T0kQlsWv</td>\n",
       "      <td>B2_T0kQlsWv_0</td>\n",
       "      <td>가만히 하늘을 살펴보면 하늘서 구름이 기장 큰 체를 한다. 사람 속살필 적 걱정이 ...</td>\n",
       "      <td>가만히 하늘을 살펴보면 하늘서 구름이 가장 큰 체를 한다.  사람 속 살필 적 걱정...</td>\n",
       "      <td>['가능하면1일1시', '190824', '임재건', '1일1시', '다시는사랑이없...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1day1poem</td>\n",
       "      <td>B2-WQRrFlNi</td>\n",
       "      <td>B2-WQRrFlNi_0</td>\n",
       "      <td>날줄 몰라도 나무 위 집은 얼마든지을수 있지. -거미집4 # 19.09.29 #가능...</td>\n",
       "      <td>날 줄 몰라도 나무 위 집은 얼마든 지을 수 있지. - 거미집4  오른다면  #가능...</td>\n",
       "      <td>['가능하면1일1시', '190929', '임재건', '1일1시', '다시는사랑이없...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1day1poem</td>\n",
       "      <td>B28u5bmlGaV</td>\n",
       "      <td>B28u5bmlGaV_0</td>\n",
       "      <td>달력은 입추부터 가을이라하고 TV는 이번 비가그치면 가을이라 하네요. 어머니는 초록...</td>\n",
       "      <td>달력은 입추부터 가을이라 하고  TV는 이번 비가 그치면 가을이라 하네요.  어머니...</td>\n",
       "      <td>['가능하면1일1시', '190823', '임재건', '1일1시', '다시는사랑이없...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     USER_ID   CONTENT_ID CONTENT_IMAGE_ID  \\\n",
       "0  1day1poem  B3B7tNPFOhY    B3B7tNPFOhY_0   \n",
       "1  1day1poem  B3A90BZlUGb    B3A90BZlUGb_0   \n",
       "2  1day1poem  B2_T0kQlsWv    B2_T0kQlsWv_0   \n",
       "3  1day1poem  B2-WQRrFlNi    B2-WQRrFlNi_0   \n",
       "4  1day1poem  B28u5bmlGaV    B28u5bmlGaV_0   \n",
       "\n",
       "                                   Image_Content_txt  \\\n",
       "0  벌레 물어 가렵다면 할머니 침을 발라주셨다. 쪼그려 앉아 다리 저릴 때도 할머니 코...   \n",
       "1  들에 억새가 은발에 구부정하니 할매 닮아서 할매랑 들에 가면 할매 못 찾겠네. -할...   \n",
       "2  가만히 하늘을 살펴보면 하늘서 구름이 기장 큰 체를 한다. 사람 속살필 적 걱정이 ...   \n",
       "3  날줄 몰라도 나무 위 집은 얼마든지을수 있지. -거미집4 # 19.09.29 #가능...   \n",
       "4  달력은 입추부터 가을이라하고 TV는 이번 비가그치면 가을이라 하네요. 어머니는 초록...   \n",
       "\n",
       "                                         Content_txt  \\\n",
       "0  벌레 물어 가렵다면 할머니 침을 발라주셨다.  쪼그려 앉아 다리 저릴 때도 할머니 ...   \n",
       "1  들에 억새가 은발에 구부정하니 할매 닮아서  할매랑 들에 가면 할매 못 찾겠네. -...   \n",
       "2  가만히 하늘을 살펴보면 하늘서 구름이 가장 큰 체를 한다.  사람 속 살필 적 걱정...   \n",
       "3  날 줄 몰라도 나무 위 집은 얼마든 지을 수 있지. - 거미집4  오른다면  #가능...   \n",
       "4  달력은 입추부터 가을이라 하고  TV는 이번 비가 그치면 가을이라 하네요.  어머니...   \n",
       "\n",
       "                                            Hashtags  \n",
       "0  ['가능하면1일1시', '190825', '임재건', '1일1시', '다시는사랑이없...  \n",
       "1  ['가능하면1일1시', '190930', '임재건', '1일1시', '다시는사랑이없...  \n",
       "2  ['가능하면1일1시', '190824', '임재건', '1일1시', '다시는사랑이없...  \n",
       "3  ['가능하면1일1시', '190929', '임재건', '1일1시', '다시는사랑이없...  \n",
       "4  ['가능하면1일1시', '190823', '임재건', '1일1시', '다시는사랑이없...  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE_Final = load_directory_data(\"Final_Data\")\n",
    "total_df = pd.DataFrame()\n",
    "\n",
    "for f in FILE_Final:\n",
    "    df =pd.read_csv(f,encoding = 'utf-8')\n",
    "    df = df.iloc[:,1:]\n",
    "    total_df = total_df.append(df,sort=True)\n",
    "    \n",
    "total_df = total_df.iloc[:,:-1]\n",
    "total_df = total_df[['USER_ID','CONTENT_ID', 'CONTENT_IMAGE_ID','Image_Content_txt','Content_txt', 'Hashtags']]\n",
    "total_df = total_df.reset_index(drop = True)\n",
    "total_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
